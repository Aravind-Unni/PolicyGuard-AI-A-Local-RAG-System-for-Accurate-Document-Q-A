{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **RAG PIPELINE USING LANGCHAIN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_classic.chains import RetrievalQA\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_ollama import ChatOllama "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### USNG HUGGINGFACE API KEY INORDER TO ACCESS THE EMBEDDING MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " API Key set manually\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"#paste key here (i removed mine) \n",
        "print(\" API Key set manually\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LOADING THE PDF FILE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " File found at: ../data/Bazaar-Return-Refund.pdf\n",
            " Successfully loaded 3 pages.\n"
          ]
        }
      ],
      "source": [
        "file_path = \"../data/Bazaar-Return-Refund.pdf\"\n",
        "\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    print(f\" File found at: {file_path}\")\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    docs = loader.load()\n",
        "    \n",
        "    print(f\" Successfully loaded {len(docs)} pages.\")\n",
        "else:\n",
        "    print(f\" File NOT found at: {file_path}\")\n",
        "    print(\"Current working directory:\", os.getcwd())\n",
        "    print(\"Files in 'data' folder:\", os.listdir(\"data\") if os.path.exists(\"data\") else \"Data folder missing\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**TEXT IN THE PDF DOCUMENTS ARE DIVIDED INTO CHUNKS (IF I DO TOKENISATION HERE,THE EMBEDDING MODEL BECOMES COMPUTATIONALLY EXPENSIVE AND DIFFICULT FOR THE LLM TO PROCESS THE TEXT AS THE TOKEN LENGTH IS LARGE)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHUNK_SIZE = 800\n",
        "CHUNK_OVERLAP = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 2: TEXT CHUNKING\n",
            "Chunk Size: 800, Overlap: 150\n",
            " Created 12 text chunks\n",
            "   Average chunk length: 648 characters\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"STEP 2: TEXT CHUNKING\")\n",
        "print(f\"Chunk Size: {CHUNK_SIZE}, Overlap: {CHUNK_OVERLAP}\")\n",
        "\n",
        "# Create text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        ")\n",
        "\n",
        "# Split documents into chunks\n",
        "if 'docs' in globals() and docs:\n",
        "    all_chunks = text_splitter.split_documents(docs)\n",
        "    \n",
        "    print(f\" Created {len(all_chunks)} text chunks\")\n",
        "    if all_chunks:\n",
        "        avg_len = sum(len(chunk.page_content) for chunk in all_chunks) // len(all_chunks)\n",
        "        print(f\"   Average chunk length: {avg_len} characters\")\n",
        "else:\n",
        "    print(\" Error: 'docs' variable is empty or not defined. Run the PDF loading cell first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LOADING THE EMBEDDING MODEL USING HUGGINGFACE API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CONFIGURE VECTOR DATABASE SETTINGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Here we define where the vector data will be stored locally:\n",
        "PERSIST_DIRECTORY = \"./chroma_db\"\n",
        "COLLECTION_NAME = \"company_policies\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EMBEDDING AND VECTOR STORAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing embedding model...\n",
            "successfully Loaded: sentence-transformers/all-MiniLM-L6-v2\n",
            "Creating Chroma vector store...\n",
            "Vector store created and saved to: ./chroma_db\n",
            "Total embeddings: 12\n"
          ]
        }
      ],
      "source": [
        "# Initialize embedding model \n",
        "print(\"Initializing embedding model...\")\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME,\n",
        "    model_kwargs={'device': 'cpu'}, \n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")\n",
        "print(f\"successfully Loaded: {EMBEDDING_MODEL_NAME}\")\n",
        "\n",
        "# 2. Create Chroma vector store\n",
        "print(\"Creating Chroma vector store...\")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    documents=all_chunks,\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=PERSIST_DIRECTORY,\n",
        "    collection_name=COLLECTION_NAME\n",
        ")\n",
        "\n",
        "print(f\"Vector store created and saved to: {PERSIST_DIRECTORY}\")\n",
        "print(f\"Total embeddings: {len(all_chunks)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QUESTION EMBEDDING AND SIMILARITY SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing retrieval with sample query...\n",
            "   Retrieved 3 relevant chunks for: 'What is the cancellation charge if I cancel a service 9 days after placing the order?'\n",
            "\n",
            "Top Result Preview:\n",
            "amount refunded to you will be less 9% than the total amount order that you paid on \n",
            "the date of placing the order. \n",
            "‚Ä¢ If you cancel your order on or after 16 days from the date of placing the order, ...\n"
          ]
        }
      ],
      "source": [
        "TOP_K = 3 # which means we will get top 3 chunk embedding that are closest (cosine similarity) to the input embedding in the vector database\n",
        "\n",
        "# Create retriever for similarity search\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_kwargs={\"k\": TOP_K}\n",
        ")\n",
        "\n",
        "# Test retrieval\n",
        "print(\"Testing retrieval with sample query...\")\n",
        "test_query = \"What is the cancellation charge if I cancel a service 9 days after placing the order?\"\n",
        "\n",
        "test_results = retriever.invoke(test_query)\n",
        "\n",
        "\n",
        "print(f\"   Retrieved {len(test_results)} relevant chunks for: '{test_query}'\")\n",
        "\n",
        "\n",
        "if test_results:\n",
        "    print(f\"\\nTop Result Preview:\\n{test_results[0].page_content[:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PROMPT ENGINEERING INORDER TO GET A REFINED OUTPUT AND AVOID HALLUCINATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt updated to reduce LLM 'chatter'.\n"
          ]
        }
      ],
      "source": [
        "structured_prompt_template = \"\"\"You are a specific Policy Assistant for Rainbow Bazaar.\n",
        "Your goal is to answer the user question based ONLY on the provided context chunks.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "USER QUESTION:\n",
        "{question}\n",
        "\n",
        "---\n",
        "STRICT RULES:\n",
        "1. **Focus:** Answer the question directly. Do not comment on the quality or repetition of the context text.\n",
        "2. **Grounding:** If the answer is found in *any* part of the context, use it. Ignore duplicates.\n",
        "3. **No Filler:** Do not start with \"I apologize\" or \"The context mentions.\" Start directly with the answer.\n",
        "4. **Citation:** Support your answer with source IDs (e.g., ).\n",
        "5. **Missing Info:** If the answer is strictly NOT in the context, say: \"I cannot find this information in the policy.\"\n",
        "\n",
        "FORMAT:\n",
        "**Answer:** [Direct Answer]\n",
        "**Details:** [Bullet points with citations]\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=structured_prompt_template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "print(\"Prompt updated to reduce LLM 'chatter'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LOADING THE LLM (llama3.2) LOCALLY USING OLLAMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to local Ollama instance...\n",
            "‚úÖ Local LLM initialized successfully: llama3.2\n",
            "\n",
            " Testing local connection...\n",
            "‚úÖ Response: Yes, ready.\n"
          ]
        }
      ],
      "source": [
        "# i installed ollama and then downloaded the LLM via command prompt to access it\n",
        "LLM_MODEL_NAME = \"llama3.2\" \n",
        "print(f\"Connecting to local Ollama instance...\")\n",
        "\n",
        "try:\n",
        "    llm = ChatOllama(\n",
        "        model=LLM_MODEL_NAME,\n",
        "        temperature=0.1,\n",
        "        # Llama 3.2 is fast, so we can ask for a good amount of detail\n",
        "        num_predict=512 \n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Local LLM initialized successfully: {LLM_MODEL_NAME}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing local LLM: {e}\")\n",
        "\n",
        "# Test immediately\n",
        "print(\"\\n Testing local connection...\")\n",
        "try:\n",
        "    test_msg = \"Are you ready to answer questions? Reply with 'Yes, ready'.\"\n",
        "    response = llm.invoke(test_msg)\n",
        "    print(f\"‚úÖ Response: {response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Connection Failed: {e}\")\n",
        "    print(\"Hint: Ensure the 'Ollama' app is running in the background!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CREATE RETRIEVAL QA CHAIN (THIS CHAIN IS USED TO CONNECT RETRIEVAL AND GENERATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QA Chain created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create the complete QA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\n",
        "        \"prompt\": PROMPT,\n",
        "        \"verbose\": False\n",
        "    },\n",
        "    return_source_documents=True,\n",
        "    input_key=\"query\"\n",
        ")\n",
        "\n",
        "print(\"QA Chain created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CREATING QUESTIONS MANUALLY FROM THE PDF AND TESTING THE OUTPUT GENERATED BY THE LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Test 2/3\n",
            "\n",
            "============================================================\n",
            "‚ùì QUESTION: what happens if i cancel my order on or after 16 days ?\n",
            "============================================================\n",
            "üîÑ Step 1: Searching relevant policy sections...\n",
            "   ‚úì Found 3 relevant chunks\n",
            "\n",
            "üîÑ Step 2: Llama 3.2 is thinking...\n",
            "\n",
            "üìù ANSWER:==================================================\n",
            "**Answer:** A cancellation fee will be charged that is 100% of the total Order value.\n",
            "\n",
            "**Details:**\n",
            "‚Ä¢ If you cancel your order on or after 16 days from the date of placing the order, a \n",
            "cancellation fee will be charged that is 100% of the total Order value.\n",
            "\n",
            "üìÑ SOURCES:=============================================\n",
            "   ‚Ä¢ ../data/Bazaar-Return-Refund.pdf (Page 1)\n",
            "============================================================\n",
            "\n",
            "üìä Test 3/3\n",
            "\n",
            "============================================================\n",
            "‚ùì QUESTION: What happens if I cancel my order before it ships\n",
            "============================================================\n",
            "üîÑ Step 1: Searching relevant policy sections...\n",
            "   ‚úì Found 3 relevant chunks\n",
            "\n",
            "üîÑ Step 2: Llama 3.2 is thinking...\n",
            "\n",
            "üìù ANSWER:==================================================\n",
            "**Answer:** You will not be charged any cancellation fee.\n",
            "\n",
            "**Details:** \n",
            "‚Ä¢ If you cancel your order BEFORE it has been shipped, you will not be charged any cancellation fee.\n",
            "\n",
            "üìÑ SOURCES:=============================================\n",
            "   ‚Ä¢ ../data/Bazaar-Return-Refund.pdf (Page 0)\n",
            "============================================================\n",
            "\n",
            "üìä Test 4/3\n",
            "\n",
            "============================================================\n",
            "‚ùì QUESTION: How long do I have to submit a return request for a product?\n",
            "============================================================\n",
            "üîÑ Step 1: Searching relevant policy sections...\n",
            "   ‚úì Found 3 relevant chunks\n",
            "\n",
            "üîÑ Step 2: Llama 3.2 is thinking...\n",
            "\n",
            "üìù ANSWER:==================================================\n",
            "**Answer:** 30 days from receipt of request.\n",
            "\n",
            "**Details:** \n",
            "‚Ä¢ All return requests, whether for refund or replacement, shall be processed and completed within 30 days from receipt of request.\n",
            "‚Ä¢ Valid only within 10 days from date of delivery of product.\n",
            "\n",
            "üìÑ SOURCES:=============================================\n",
            "   ‚Ä¢ ../data/Bazaar-Return-Refund.pdf (Page 0)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def ask_question(question):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"‚ùì QUESTION: {question}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    try:\n",
        "        #Similarity Search\n",
        "        print(\"üîÑ Step 1: Searching relevant policy sections...\")\n",
        "        similar_chunks = retriever.invoke(question)\n",
        "        print(f\"   ‚úì Found {len(similar_chunks)} relevant chunks\")\n",
        "        \n",
        "        #Generation\n",
        "        print(\"\\nüîÑ Step 2: Llama 3.2 is thinking...\")\n",
        "        result = qa_chain.invoke({\"query\": question})\n",
        "        \n",
        "        # Display Result\n",
        "        answer = result['result'].strip()\n",
        "        \n",
        "        print(\"\\n\" + \"üìù \" + \"ANSWER:\" + \"=\"*50)\n",
        "        # Check if answer is empty\n",
        "        if not answer:\n",
        "            print(\"‚ö†Ô∏è [The LLM returned an empty answer. Try increasing 'num_predict' in Step 8]\")\n",
        "        else:\n",
        "            print(answer)\n",
        "        \n",
        "        print(\"\\n\" + \"üìÑ \" + \"SOURCES:\" + \"=\"*45)\n",
        "        sources_used = set()\n",
        "        for doc in result['source_documents']:\n",
        "            src = doc.metadata.get('source', 'Unknown')\n",
        "            page = doc.metadata.get('page', '0') \n",
        "            sources_used.add(f\"{src} (Page {page})\")\n",
        "        \n",
        "        for source in sources_used:\n",
        "            print(f\"   ‚Ä¢ {source}\")\n",
        "            \n",
        "        print(\"=\"*60)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "# Sample questions based on company policies\n",
        "sample_questions = [\n",
        "    \"what happens if i cancel my order on or after 16 days ?\",\n",
        "    \"What happens if I cancel my order before it ships\",\n",
        "    \"How long do I have to submit a return request for a product?\",\n",
        "    \"How long does it take for a refund to appear in my account?\",\n",
        "    \"What details must I include in a return request?\",\n",
        "    \"What is the cancellation fee for services if I cancel between 7 and 15 days after ordering\",\n",
        "    \"Can a person under the age of 18 purchase items on the marketplace?\",\n",
        "    \"What email address should I use for general support or inquiries?\",\n",
        "    \"Are taxes included in the prices listed on the website?\",\n",
        "    \"Which court has jurisdiction over legal disputes related to these policies?\"\n",
        "]\n",
        "\n",
        "# Test first 3 questions\n",
        "for i, question in enumerate(sample_questions[:3], 2):\n",
        "    print(f\"\\nüìä Test {i}/3\")\n",
        "    ask_question(question)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CREATING GOLDEN DATASET FOR EVALUATION (MANUALLY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined 9 evaluation questions.\n"
          ]
        }
      ],
      "source": [
        "eval_dataset = [\n",
        "    # TYPE 1: FULLY ANSWERABLE (EASY)\n",
        "    {\n",
        "        \"type\": \"Answerable\",\n",
        "        \"question\": \"What is the time limit for submitting a return request after delivery?\",\n",
        "        \"expected\": \"10 days\"\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"Answerable\",\n",
        "        \"question\": \"Which court has exclusive jurisdiction over disputes?\",\n",
        "        \"expected\": \"Courts at Delhi\"\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"Answerable\",\n",
        "        \"question\": \"Are taxes like GST included in the listed prices?\",\n",
        "        \"expected\": \"Yes, prices are inclusive of VAT/CST, service tax, GST, duties, and cesses\"\n",
        "    },\n",
        "\n",
        "    # TYPE 2:CONDITIONAL / TRICKY (Medium) \n",
        "    {\n",
        "        \"type\": \"Conditional\",\n",
        "        \"question\": \"I want to cancel a service order 9 days after placing it. What is the fee?\",\n",
        "        \"expected\": \"9% of the total amount (Fee percentage equals number of days for cancellations between 7-15 days)\"\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"Conditional\",\n",
        "        \"question\": \"What happens if I cancel a product order after it has already been shipped?\",\n",
        "        \"expected\": \"It is treated as a Return with all applicable fees\"\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"Conditional\",\n",
        "        \"question\": \"I refused delivery of an order. How much is the cancellation fee?\",\n",
        "        \"expected\": \"100% of the total Order value (unless evidenced that product was tampered/faulty)\"\n",
        "    },\n",
        "\n",
        "    # TYPE 3: UNANSWERABLE / OUT OF SCOPE (Hard) \n",
        "    {\n",
        "        \"type\": \"Unanswerable\",\n",
        "        \"question\": \"What payment methods do you accept (e.g., Credit Card, PayPal)?\",\n",
        "        \"expected\": \"I cannot find this information (Policy mentions taxes/fees but not specific payment methods)\"\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"Unanswerable\",\n",
        "        \"question\": \"What is the customer support phone number?\",\n",
        "        \"expected\": \"I cannot find this information (Only the email rb@thepridecircle.com is provided)\"\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"Unanswerable\",\n",
        "        \"question\": \"Do you ship internationally?\",\n",
        "        \"expected\": \"I cannot find this information (Policy mentions Indian laws/taxes but does not specify shipping destinations)\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"Defined {len(eval_dataset)} evaluation questions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EVALUATION USING LLM-as-a-Judge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM Judge function initialized.\n"
          ]
        }
      ],
      "source": [
        "# 1. Define the Grading Prompt\n",
        "grading_prompt = \"\"\"You are a strict teacher grading an exam. \n",
        "Compare the ACTUAL ANSWER with the EXPECTED ANSWER.\n",
        "\n",
        "Question: {question}\n",
        "Expected Answer: {expected}\n",
        "Actual Answer: {actual}\n",
        "\n",
        "Rules:\n",
        "- Grade 1: Completely wrong or hallucinated.\n",
        "- Grade 3: Partially correct but missing key details.\n",
        "- Grade 5: Perfect match (ignoring phrasing differences).\n",
        "\n",
        "Reply ONLY with the number (1, 2, 3, 4, or 5). Do not write words.\"\"\"\n",
        "\n",
        "def grade_answer(question, actual, expected):\n",
        "    \"\"\"Uses the LLM to score the answer quality\"\"\"\n",
        "    # Create the prompt text\n",
        "    final_prompt = grading_prompt.format(\n",
        "        question=question, \n",
        "        expected=expected, \n",
        "        actual=actual\n",
        "    )\n",
        "    \n",
        "    # Ask the LLM to grade\n",
        "    try:\n",
        "        score_response = llm.invoke(final_prompt)\n",
        "        score_text = score_response.content.strip()\n",
        "        import re\n",
        "        match = re.search(r'\\d', score_text)\n",
        "        return int(match.group()) if match else 1\n",
        "    except:\n",
        "        return 1\n",
        "\n",
        "print(\"LLM Judge function initialized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### COMPREHENSIVE EVALUATION & REPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä RUNNING FINAL EVALUATION...\n",
            "\n",
            "================================================================================\n",
            "DETAILED REPORT\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Question</th>\n",
              "      <th>Model Answer</th>\n",
              "      <th>Expected</th>\n",
              "      <th>Pass/Fail</th>\n",
              "      <th>Clarity (1-5)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Answerable</td>\n",
              "      <td>What is the time limit for submitting a return...</td>\n",
              "      <td>**Answer:** 10 days from date of delivery of p...</td>\n",
              "      <td>10 days</td>\n",
              "      <td>‚úÖ PASS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Answerable</td>\n",
              "      <td>Which court has exclusive jurisdiction over di...</td>\n",
              "      <td>**Answer:** Courts at Delhi.\\n\\n**Details:** \\...</td>\n",
              "      <td>Courts at Delhi</td>\n",
              "      <td>‚úÖ PASS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Answerable</td>\n",
              "      <td>Are taxes like GST included in the listed prices?</td>\n",
              "      <td>**Answer:** Yes\\n**Details:** \\n* All prices a...</td>\n",
              "      <td>Yes, prices are inclusive of VAT/CST, service ...</td>\n",
              "      <td>‚úÖ PASS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Conditional</td>\n",
              "      <td>I want to cancel a service order 9 days after ...</td>\n",
              "      <td>**Answer:** 100% of the total Order value.\\n\\n...</td>\n",
              "      <td>9% of the total amount (Fee percentage equals ...</td>\n",
              "      <td>‚úÖ PASS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Conditional</td>\n",
              "      <td>What happens if I cancel a product order after...</td>\n",
              "      <td>**Answer:** You will be charged a cancellation...</td>\n",
              "      <td>It is treated as a Return with all applicable ...</td>\n",
              "      <td>‚úÖ PASS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Conditional</td>\n",
              "      <td>I refused delivery of an order. How much is th...</td>\n",
              "      <td>**Answer:** 100% of the total Order value.\\n\\n...</td>\n",
              "      <td>100% of the total Order value (unless evidence...</td>\n",
              "      <td>‚úÖ PASS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Unanswerable</td>\n",
              "      <td>What payment methods do you accept (e.g., Cred...</td>\n",
              "      <td>**Answer:** Credit Card and PayPal.\\n\\n**Detai...</td>\n",
              "      <td>I cannot find this information (Policy mention...</td>\n",
              "      <td>‚úÖ PASS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Unanswerable</td>\n",
              "      <td>What is the customer support phone number?</td>\n",
              "      <td>**Answer:** I cannot find this information in ...</td>\n",
              "      <td>I cannot find this information (Only the email...</td>\n",
              "      <td>‚úÖ PASS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Unanswerable</td>\n",
              "      <td>Do you ship internationally?</td>\n",
              "      <td>**Answer:** No\\n**Details:** \\n* The applicati...</td>\n",
              "      <td>I cannot find this information (Policy mention...</td>\n",
              "      <td>‚ùå FAIL</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Type                                           Question  \\\n",
              "0    Answerable  What is the time limit for submitting a return...   \n",
              "1    Answerable  Which court has exclusive jurisdiction over di...   \n",
              "2    Answerable  Are taxes like GST included in the listed prices?   \n",
              "3   Conditional  I want to cancel a service order 9 days after ...   \n",
              "4   Conditional  What happens if I cancel a product order after...   \n",
              "5   Conditional  I refused delivery of an order. How much is th...   \n",
              "6  Unanswerable  What payment methods do you accept (e.g., Cred...   \n",
              "7  Unanswerable         What is the customer support phone number?   \n",
              "8  Unanswerable                       Do you ship internationally?   \n",
              "\n",
              "                                        Model Answer  \\\n",
              "0  **Answer:** 10 days from date of delivery of p...   \n",
              "1  **Answer:** Courts at Delhi.\\n\\n**Details:** \\...   \n",
              "2  **Answer:** Yes\\n**Details:** \\n* All prices a...   \n",
              "3  **Answer:** 100% of the total Order value.\\n\\n...   \n",
              "4  **Answer:** You will be charged a cancellation...   \n",
              "5  **Answer:** 100% of the total Order value.\\n\\n...   \n",
              "6  **Answer:** Credit Card and PayPal.\\n\\n**Detai...   \n",
              "7  **Answer:** I cannot find this information in ...   \n",
              "8  **Answer:** No\\n**Details:** \\n* The applicati...   \n",
              "\n",
              "                                            Expected Pass/Fail  Clarity (1-5)  \n",
              "0                                            10 days    ‚úÖ PASS              5  \n",
              "1                                    Courts at Delhi    ‚úÖ PASS              5  \n",
              "2  Yes, prices are inclusive of VAT/CST, service ...    ‚úÖ PASS              5  \n",
              "3  9% of the total amount (Fee percentage equals ...    ‚úÖ PASS              3  \n",
              "4  It is treated as a Return with all applicable ...    ‚úÖ PASS              3  \n",
              "5  100% of the total Order value (unless evidence...    ‚úÖ PASS              3  \n",
              "6  I cannot find this information (Policy mention...    ‚úÖ PASS              3  \n",
              "7  I cannot find this information (Only the email...    ‚úÖ PASS              4  \n",
              "8  I cannot find this information (Policy mention...    ‚ùå FAIL              3  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            " FINAL PROJECT REPORT CARD\n",
            "==================================================\n",
            " OVERALL ACCURACY:        88.9%\n",
            " HALLUCINATION AVOIDANCE: 66.7%\n",
            " ANSWER CLARITY:          75.6% (3.8/5)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"üìä RUNNING FINAL EVALUATION...\")\n",
        "\n",
        "results_data = []\n",
        "\n",
        "\n",
        "for item in eval_dataset:\n",
        "    # Get Model Response\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        response = qa_chain.invoke({\"query\": item['question']})\n",
        "        latency = round(time.time() - start_time, 2)\n",
        "        actual_answer = response['result'].strip()\n",
        "    except:\n",
        "        actual_answer = \"ERROR\"\n",
        "        latency = 0\n",
        "\n",
        "    # Determine \"Pass/Fail\" \n",
        "    # If Unanswerable: Pass if it says \"cannot find/no info\"\n",
        "    # If Answerable: Pass if it contains key words from expected answer\n",
        "    is_correct = False\n",
        "    \n",
        "    if item['type'] == \"Unanswerable\":\n",
        "        valid_refusals = [\"cannot find\", \"not mention\", \"no information\", \"does not specify\", \"context does not\"]\n",
        "        if any(phrase in actual_answer.lower() for phrase in valid_refusals):\n",
        "            is_correct = True \n",
        "    else:\n",
        "        keywords = item['expected'].split()[:3]\n",
        "        if any(k.lower() in actual_answer.lower() for k in keywords):\n",
        "            is_correct = True\n",
        "\n",
        "    # Get Clarity Score (Using LLM Judge function)\n",
        "    #(If grade_answer fails or isn't defined, default to 3)\n",
        "    try:\n",
        "        clarity_score = grade_answer(item['question'], actual_answer, item['expected'])\n",
        "    except:\n",
        "        clarity_score = 3 \n",
        "\n",
        "    results_data.append({\n",
        "        \"Type\": item['type'],\n",
        "        \"Question\": item['question'],\n",
        "        \"Model Answer\": actual_answer,\n",
        "        \"Expected\": item['expected'],\n",
        "        \"Pass/Fail\": \"‚úÖ PASS\" if is_correct else \"‚ùå FAIL\",\n",
        "        \"Clarity (1-5)\": clarity_score\n",
        "    })\n",
        "\n",
        "# CREATE DATAFRAME & SHOW DETAILED REPORT\n",
        "df_final = pd.DataFrame(results_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DETAILED REPORT\")\n",
        "print(\"=\"*80)\n",
        "display(df_final)\n",
        "\n",
        "# 3. CALCULATE METRICS\n",
        "# Accuracy\n",
        "total = len(df_final)\n",
        "passed = len(df_final[df_final[\"Pass/Fail\"] == \"‚úÖ PASS\"])\n",
        "accuracy = (passed / total) * 100\n",
        "\n",
        "#Hallucination Avoidance\n",
        "# (% of Unanswerable questions that were correctly refused)\n",
        "unanswerable_df = df_final[df_final[\"Type\"] == \"Unanswerable\"]\n",
        "if len(unanswerable_df) > 0:\n",
        "    correct_refusals = len(unanswerable_df[unanswerable_df[\"Pass/Fail\"] == \"‚úÖ PASS\"])\n",
        "    hallucination_score = (correct_refusals / len(unanswerable_df)) * 100\n",
        "else:\n",
        "    hallucination_score = 100.0\n",
        "\n",
        "# Answer Clarity\n",
        "# (Average of the 1-5 scores converted to %)\n",
        "avg_clarity_score = df_final[\"Clarity (1-5)\"].mean()\n",
        "clarity_pct = (avg_clarity_score / 5) * 100\n",
        "\n",
        "# 4. PRINT FINAL METRICS CARD\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" FINAL PROJECT REPORT CARD\")\n",
        "print(\"=\"*50)\n",
        "print(f\" OVERALL ACCURACY:        {accuracy:.1f}%\")\n",
        "print(f\" HALLUCINATION AVOIDANCE: {hallucination_score:.1f}%\")\n",
        "print(f\" ANSWER CLARITY:          {clarity_pct:.1f}% ({avg_clarity_score:.1f}/5)\")\n",
        "print(\"=\"*50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EDGE CASE HANDLING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            " EDGE CASE TEST: Hallucination Avoidance\n",
            "============================================================\n",
            "Question: Who is the CEO of Rainbow Bazaar?\n",
            "Thinking...\n",
            "\n",
            "Model Response:\n",
            "'I cannot find this information in the policy.'\n",
            "\n",
            "‚úÖ SUCCESS: The model admitted it doesn't know.\n"
          ]
        }
      ],
      "source": [
        "print(\" EDGE CASE TEST: Hallucination Avoidance\")\n",
        "\n",
        "\n",
        "# This question is definitely NOT in the document\n",
        "trick_question = \"Who is the CEO of Rainbow Bazaar?\"\n",
        "\n",
        "print(f\"Question: {trick_question}\")\n",
        "print(\"Thinking...\")\n",
        "\n",
        "response = qa_chain.invoke({\"query\": trick_question})\n",
        "final_answer = response['result'].strip()\n",
        "\n",
        "print(f\"\\nModel Response:\\n'{final_answer}'\")\n",
        "\n",
        "if \"cannot find\" in final_answer.lower() or \"not provided\" in final_answer.lower():\n",
        "    print(\"\\n‚úÖ SUCCESS: The model admitted it doesn't know.\")\n",
        "else:\n",
        "    print(\"\\n‚ùå FAILURE: The model hallucinated an answer!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "openaidemo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
